{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "authors_id = -1\n",
    "books_id = -1\n",
    "address_id = -1\n",
    "customers_id = -1\n",
    "orders_id = -1\n",
    "order_items_id = -1\n",
    "\n",
    "tables = ['authors', 'books', 'addresses', 'customers', 'orders', 'order_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_authors():\n",
    "    global authors_id\n",
    "    with open('csv/authors.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'first_name', 'last_name', 'bio']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(100):\n",
    "            authors_id += 1\n",
    "            writer.writerow({'id': authors_id, 'first_name': fake.first_name(), 'last_name': fake.last_name(), 'bio': fake.text()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_books():\n",
    "    global books_id\n",
    "    with open('csv/books.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'title', 'genres', 'published_at', 'price', 'stock', 'author_id']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(1000):\n",
    "            books_id += 1\n",
    "            writer.writerow({'id': books_id, 'title': fake.sentence(), 'genres': fake.text(), 'published_at': fake.date_time_this_decade(), 'price': random.uniform(1, 100), 'stock': random.randint(1, 100), 'author_id': random.randint(0, authors_id)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_address():\n",
    "    global address_id\n",
    "    with open('csv/addresses.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'street', 'city', 'state', 'postal_code', 'country']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(100):\n",
    "            address_id += 1\n",
    "            writer.writerow({'id': address_id, 'street': fake.street_address(), 'city': fake.city(), 'state': fake.state(), 'postal_code': fake.postcode(), 'country': fake.country()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customers():\n",
    "    global customers_id\n",
    "    with open('csv/customers.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'name', 'email', 'created_at', 'address_id']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(100):\n",
    "            customers_id += 1\n",
    "            writer.writerow({'id': customers_id, 'name': fake.name(), 'email': fake.email(), 'created_at': fake.date_time_this_decade(), 'address_id': random.randint(0, address_id)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_orders():\n",
    "    global orders_id\n",
    "    with open('csv/orders.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'customer_id', 'total_price', 'created_at', 'status']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(100):\n",
    "            orders_id += 1\n",
    "            writer.writerow({'id': orders_id, 'customer_id': random.randint(0, customers_id), 'total_price': random.uniform(1, 100), 'created_at': fake.date_time_this_decade(), 'status': fake.word()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_order_items():\n",
    "    global order_items_id\n",
    "    with open('csv/order_items.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'order_id', 'book_id', 'quantity']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(100):\n",
    "            order_items_id += 1\n",
    "            writer.writerow({'id': order_items_id, 'order_id': random.randint(0, orders_id), 'book_id': random.randint(0, books_id), 'quantity': random.randint(1, 100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_authors()\n",
    "generate_books()\n",
    "generate_address()\n",
    "generate_customers()\n",
    "generate_orders()\n",
    "generate_order_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_sql_insert(csv_file):\n",
    "    table_name = csv_file.replace(\".csv\", \"\")\n",
    "\n",
    "    with open(\"csv/\" + csv_file, 'r', newline='', encoding='latin1') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        columns = csv_reader.fieldnames\n",
    "        \n",
    "        x = str(tuple(columns)).replace(\"'\", \"\") \n",
    "        insert_queries = []\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            values = [f\"{row[column]}\" if isinstance(row[column], str) else str(row[column]) for column in columns]\n",
    "            y = str(tuple(values)).replace(\"'NULL'\", \"NULL\")\n",
    "            insert_query = f'INSERT INTO {table_name} {x} VALUES {y};'\n",
    "            insert_queries.append(insert_query)\n",
    "\n",
    "    return insert_queries \n",
    "\n",
    "\n",
    "insert_queries = []\n",
    "\n",
    "for tablename in tables:\n",
    "    insert_queries += csv_to_sql_insert(f\"{tablename}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Syncronisator = \"\"\"\n",
    "CREATE OR REPLACE PROCEDURE sync_serial_sequence(table_name TEXT, column_name TEXT)\n",
    "LANGUAGE plpgsql\n",
    "AS $$\n",
    "DECLARE\n",
    "    sequence_name TEXT;\n",
    "    max_value BIGINT;\n",
    "BEGIN\n",
    "    SELECT pg_get_serial_sequence(table_name, column_name) INTO sequence_name;\n",
    "\n",
    "    IF sequence_name IS NULL THEN\n",
    "        RAISE EXCEPTION 'No sequence found for table \"%\" and column \"%\"', table_name, column_name;\n",
    "    END IF;\n",
    "\n",
    "    EXECUTE FORMAT('SELECT COALESCE(MAX(%I), 0) FROM %I', column_name, table_name) INTO max_value;\n",
    "    EXECUTE FORMAT('SELECT SETVAL(%L, %s)', sequence_name, max_value + 1);\n",
    "    RAISE NOTICE 'Sequence \"%\" synchronized to %', sequence_name, max_value + 1;\n",
    "END;\n",
    "$$;\n",
    "\n",
    "CALL sync_serial_sequence('authors', 'id');\n",
    "CALL sync_serial_sequence('books', 'id');\n",
    "CALL sync_serial_sequence('addresses', 'id');\n",
    "CALL sync_serial_sequence('customers', 'id');\n",
    "CALL sync_serial_sequence('orders', 'id');\n",
    "CALL sync_serial_sequence('order_items', 'id');\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../../sql/database-dummyloader.sql\", \"w+\", encoding='utf-8') as file:\n",
    "    for query in insert_queries:\n",
    "        file.write(query + \"\\n\")\n",
    "\n",
    "    file.write(Syncronisator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
